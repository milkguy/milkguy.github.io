<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>乔治学习笔记</title>
    <link href="/2024/02/07/%E4%B9%94%E6%B2%BB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/02/07/%E4%B9%94%E6%B2%BB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="第六节课"><a href="#第六节课" class="headerlink" title="第六节课"></a>第六节课</h2><ul><li>课堂笔记</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>深度学习入门指北</title>
    <link href="/2023/06/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/"/>
    <url>/2023/06/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<p>本文将把我的深度学习入门经历分享给你，希望能帮助到正在前进路上昂首前行的你。学习深度学习首先要学会熟练使用python的基本语法，在这里我默认你已经学完了python基本语法</p><span id="more"></span><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>工欲善其事，必现利其器。学习一门新技术的时候，首先要配置开发环境，首先我们要配置pytorch环境，因为我用的是mac m1开发，所以在这里我只介绍mac版本下的环境配置，如果你用的是windows或者ubuntu操作系统，请自行学习版本环境配置。</p><p>anaconda相当于配置一套单独的开发环境</p><ul><li>首先要安装anaconda环境<ul><li>conda create -n pytorch python&#x3D;3.8 创建新的conda环境</li><li>conda activate pytorch 切换到pytorch环境</li><li>pip list 查看安装的工具包</li></ul></li><li>python ide安装<ul><li>pycharm<ul><li>使用python console可以动态输出代码</li></ul></li><li>jupyter<ul><li>主要使用的工具包是ipykernel</li><li>conda install nb_conda</li><li>jupyter notebook 启动jupyter</li></ul></li><li>conda install –use-local name 安装python包</li></ul></li></ul><h2 id="工具箱"><a href="#工具箱" class="headerlink" title="工具箱"></a>工具箱</h2><p>dir：打开pytorch工具箱，看到里面的内容，类似于点一样，一直往下点</p><p>help：说明功能，类似于功能说明一样</p><p><img src="/../../../source/picture/image-20230619111716432.png" alt="image-20230619111716432"></p><h2 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h2><ul><li>dataset：提供一种获取数据和label的方式</li><li>dataloader：对数据打包之后一起加载到网络中，为网络提供不同的数据形式</li></ul><h2 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h2><ul><li>可以用来生成折线图，也可以用来显示图片</li><li>常用的方法有两种<ul><li>writer.add_scalar</li><li>writer.add_image</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=2x&quot;</span>, i, <span class="hljs-number">2</span>*i)<br>writer.close()<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>img_path = <span class="hljs-string">&quot;dataset/train/ants_image/5650366_e22b7e1065.jpg&quot;</span><br>img = Image.<span class="hljs-built_in">open</span>(img_path)<br>img_array = np.array(img)<br>writer.add_image(<span class="hljs-string">&quot;test&quot;</span>, img_array, <span class="hljs-number">2</span>, dataformats=<span class="hljs-string">&quot;HWC&quot;</span>)<br><br>writer.close()<br></code></pre></td></tr></table></figure><h2 id="Transformers-处理图像"><a href="#Transformers-处理图像" class="headerlink" title="Transformers 处理图像"></a>Transformers 处理图像</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>img_path = <span class="hljs-string">&quot;dataset/train/ants_image/0013035.jpg&quot;</span><br>img = Image.<span class="hljs-built_in">open</span>(img_path)<br><br><span class="hljs-comment"># ToTensor</span><br>trans_tensor = transforms.ToTensor()<br>tensor_img = trans_tensor(img)<br><br><span class="hljs-built_in">print</span>(tensor_img)<br>writer.add_image(<span class="hljs-string">&quot;ToTensor&quot;</span>, tensor_img, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Normalize</span><br>trans_nor = transforms.Normalize([<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>])<br>trans_nor_img = trans_nor(tensor_img)<br>writer.add_image(<span class="hljs-string">&quot;Normalize&quot;</span>, trans_nor_img, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Resize</span><br>trans_resize = transforms.Resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))<br>trans_size_img = trans_resize(img)<br>trans_resize_img_totensor = trans_tensor(trans_size_img)<br>writer.add_image(<span class="hljs-string">&quot;trans_nor_resize&quot;</span>, trans_resize_img_totensor, <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Compose</span><br>trans_resize_2 = transforms.Resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))<br>trans_compose = transforms.Compose([trans_resize_2, trans_tensor])<br>img_resize_2 = trans_compose(img)<br>writer.add_image(<span class="hljs-string">&quot;Resize&quot;</span>, img_resize_2, <span class="hljs-number">2</span>)<br><br><br><span class="hljs-comment"># RandomCrop</span><br>trans_random = transforms.RandomCrop(<span class="hljs-number">512</span>)<br>trans_compose_2 = transforms.Compose([trans_random, trans_tensor])<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    img_random = trans_compose_2(img)<br>    writer.add_image(<span class="hljs-string">&quot;RandomCrop&quot;</span>, img_random, i)<br><br>writer.close()<br></code></pre></td></tr></table></figure><h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br>dataset_transform = torchvision.transforms.Compose([<br>    transforms.ToTensor()<br>])<br>train_set = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;./datasets&quot;</span>, train=<span class="hljs-literal">True</span>, transform=dataset_transform, download=<span class="hljs-literal">True</span>)<br>test_set = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;./datasets&quot;</span>, train=<span class="hljs-literal">False</span>, transform=dataset_transform, download=<span class="hljs-literal">True</span>)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs2&quot;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5000</span>):<br>    img, target = train_set[i]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img))<br>    writer.add_image(<span class="hljs-string">&quot;test&quot;</span>, img, i)<br>writer.close()<br></code></pre></td></tr></table></figure><h2 id="dataloader"><a href="#dataloader" class="headerlink" title="dataloader"></a>dataloader</h2><ul><li>batch_size：判断每次读取几条数据打包成一个集合</li><li>dataset：输入的图片的集合</li><li>shuffle：多次加载顺序是否打乱</li><li>drop_last：最后的内容是否要删除</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./datasets&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br>test_loader = DataLoader(dataset=test_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, drop_last=<span class="hljs-literal">False</span>)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;dataloader&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;test_data&quot;</span>, imgs, step)<br>    step += <span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(imgs)<br>    <span class="hljs-built_in">print</span>(targets)<br><br>writer.close()<br></code></pre></td></tr></table></figure><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><ul><li>卷积运算：矩阵相乘再相加</li></ul><p><img src="/../../../source/picture/image-20230630093705805.png" alt="image-20230630093705805"></p><h2 id="最大池化操作"><a href="#最大池化操作" class="headerlink" title="最大池化操作"></a>最大池化操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> MaxPool2d<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./datasets&quot;</span>, transform=torchvision.transforms.ToTensor(), train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span> ,<span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                      [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]], dtype=<span class="hljs-built_in">float</span>)<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Tudui, self).__init__()<br>        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.maxpool1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br>tudui = Tudui()<br><br>output = tudui(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs_maxpool&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    output = tudui(imgs)<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h2 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h2><ul><li>小于0的数转化成0</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> ReLU<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, -<span class="hljs-number">0.5</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Tudui, self).__init__()<br>        self.relu1 = ReLU()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.relu1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br>tudui = Tudui()<br>output = tudui(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><ul><li>非线性激活层</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.datasets<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> ReLU, Sigmoid<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, -<span class="hljs-number">0.5</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)<br><br>dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./datasets&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Tudui, self).__init__()<br>        self.relu1 = ReLU()<br>        self.sigmoid1 = Sigmoid()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.sigmoid1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;nn_relu&quot;</span>)<br><br>tudui = Tudui()<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    output = tudui(imgs)<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step += <span class="hljs-number">1</span><br><br>writer.close()<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure><h2 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h2><p><img src="/../../../source/picture/image-20230703135911572.png" alt="image-20230703135911572"></p><ul><li>input_feature：4096</li><li>Output_feature：1000</li></ul><p>cmake <br>  -DCMAKE_SYSTEM_PROCESSOR&#x3D;arm64 <br>  -DCMAKE_OSX_ARCHITECTURES&#x3D;arm64 <br>  -DWITH_OPENJPEG&#x3D;OFF <br>  -DWITH_IPP&#x3D;OFF <br>  -DCMAKE_BUILD_TYPE&#x3D;RELEASE <br>  -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local <br>  -DOPENCV_EXTRA_MODULES_PATH&#x3D;$HOME&#x2F;opencv_contrib-4..0&#x2F;modules <br>  -DPYTHON2_EXECUTABLE&#x3D;&#x2F;dev&#x2F;null <br>  -DPYTHON3_EXECUTABLE&#x3D;$HOME&#x2F;anaconda3&#x2F;bin&#x2F;python3 <br>  -DBUILD_opencv_python2&#x3D;OFF <br>  -DBUILD_opencv_python3&#x3D;ON <br>  -DINSTALL_PYTHON_EXAMPLES&#x3D;ON <br>  -DINSTALL_C_EXAMPLES&#x3D;OFF <br>  -DOPENCV_ENABLE_NONFREE&#x3D;ON <br>  -DBUILD_EXAMPLES&#x3D;ON ..</p><p><strong>视频智能编辑发布服务器</strong><br><strong>(1)提供2台用于支撑视频智能编辑和内容智能检测的高性能GPU服务器。每台服务器配置要求：满足国产化自主可控需求，标准2U机架式服务器，配置不少于2路自主可控CPU，每颗CPU≥64核，主频≥2.1GHz，配置不少于512GB DDR4内存，可通过加装内存条方式扩容至1TB，SSD硬盘裸容量不低于7.68T，机械硬盘裸容量不低于36T、转速不低于7.2K，Raid有SAS 2G缓存和RAID0、RAID1、RAID5等，GPU显卡不低于64G显存、不少于2块，配置双口万兆网卡（光纤接口）不少于1个，配置2个电源模块，支持热插拔，安装有授权国产自主可控操作系统。</strong></p><h1 id="环境搭建-1"><a href="#环境搭建-1" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>安装anaconda，包管理工具</p><p>安装pycharm</p><p>安装pytorch</p><p>配置jupyter</p><p>​</p><h1 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h1><ul><li><p>dataset</p></li><li><p>dataloader</p></li><li><p>模型数据加载操作</p></li><li><p>Tensorboard 模型数据操作</p><ul><li>绘制图形</li><li>导入图片</li></ul></li><li><p>transforms 对图片的格式进行处理</p></li><li><p>tensor</p></li><li><p><img src="/../../../source/picture/image-20230605154253340.png" alt="image-20230605154253340"></p></li></ul><p><img src="/../../../source/picture/image-20230605155157673.png" alt="image-20230605155157673"></p><p>Transforms.Normalize() 归一化处理</p><p>transforms 对图片进行处理</p><p>Torchvision</p><p>dataset：使用开源数据集</p><p>自定义数据集</p><ul><li>dataloader 加载数据集</li><li>Dataset：数据集</li><li>Batch_size：每次多少张牌</li><li>shuffle：牌的顺序</li></ul><p>torch.nn 神经网络</p><p>torch.nn.function</p><ul><li><p>卷积运算，主要是做矩阵的乘法然后再相加</p></li><li><p>stride：矩阵运算每次移动的位置</p></li><li><p>padding: 外层加一圈，默认数字是1</p></li></ul><p>神经网络</p><ul><li>卷积操作<ul><li>in_channels 输入图像的通道数</li><li>out_channels 输出通道数</li><li>Kernel_size 卷积和的尺寸大小</li><li>stride 卷积过程中的步径大小</li><li>Padding: 边缘是否需要填充</li><li>padding_mode：控制padding是以什么样的方式填充</li><li>dilation：卷积过程中和中间的距离</li><li>groups：1</li><li>bias：true， 加一个偏执</li></ul></li></ul><p>卷积层</p><p>池化层</p><p>最大池化技术 Maxpool2d</p><p>非线性激活</p><p>正则化层</p><p>Recurrent层 一种特定的网络结构</p><p>线性层</p><p>Dropout层 防止过拟合 自然语言处理中常用</p><p>Vgg16</p><p>sequential 对同一个神经网络进行多次不同的操作</p><p>损失函数和反向传播</p><p>loss function 损失函数 Loss越小越好，经过不断训练</p><p>使用pytorch提供的网络进行训练</p><p>优化器</p><p>选择对应的优化器算法，放入模型的参数，学习速率，需要设置的参数</p><p><img src="/../../../source/picture/image-20230612150651419.png" alt="image-20230612150651419"></p><p>* </p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>解读程序是怎样跑起来的</title>
    <link href="/2022/07/28/%E8%A7%A3%E8%AF%BB%E7%A8%8B%E5%BA%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E8%B7%91%E8%B5%B7%E6%9D%A5%E7%9A%84/"/>
    <url>/2022/07/28/%E8%A7%A3%E8%AF%BB%E7%A8%8B%E5%BA%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E8%B7%91%E8%B5%B7%E6%9D%A5%E7%9A%84/</url>
    
    <content type="html"><![CDATA[<p>本文解读图灵系列丛书程序是怎样跑起来的</p><span id="more"></span><h2 id="什么是CPU？"><a href="#什么是CPU？" class="headerlink" title="什么是CPU？"></a>什么是CPU？</h2><p>​对于学计算机的我们来说，首次听到CPU的时候应该是一个非常高级的概念，并不了解到底什么事CPU，也不了解CPU内部都干了些什么事儿，这一部分，我带着大家慢慢来理解。</p><p>​众所周知，CPU内部是数百万至数亿个晶体管构成的，在CPU的内部，是由<strong>寄存器</strong>、<strong>控制器</strong>、<strong>运算器</strong>、<strong>时钟</strong>四部分构成的</p><p><img src="/../picture/image-20220730181208538.png" alt="CPU的内部构造"></p><ul><li>寄存器：用来暂存数据和指令</li><li>控制器：把内存上的指令和数据，读入寄存器中，并根据指令的执行结果来控制整个计算机</li><li>运算器：运算从内存中读入到寄存器中的数据</li><li>时钟：发出CPU开始计时的时钟信号</li></ul><p>​大家是否对CPU有了一定的认识和了解，那么接下来我们来了解一下什么是内存，内存就是我们常说的主存，用来存储指令和数据，内存当中的每一个字节都有一个地址编号，CPU通过这个地址来读取内存当中的指令和数据，存储在硬盘上的应用程序需要传输到内存上才能运行，当计算机关机之后，内存上的数据也自动清除。</p><h3 id="CPU是寄存器的集合体"><a href="#CPU是寄存器的集合体" class="headerlink" title="CPU是寄存器的集合体"></a>CPU是寄存器的集合体</h3><p>​其实对于计算机来说，识别不了我们日常编写的C语言、C++、Java等高级编程语言，计算机只能识别机器语言，机器语言就是一些计算机能识别的01代码串，机器语言级别的程序主要是通过寄存器来处理的,计算机底层语言汇编语言与机器语言的指令基本上是一一对应的，将汇编语言转化为机器语言这一过程称为汇编，反之则称为反汇编。</p><p><img src="/../picture/image-20220730182853527.png" alt="CPU中寄存器的种类和功能"></p><h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>​程序计数器想必大家都没听过，程序计数器存储了下一条指令所在的内存地址，所以程序计数器主要是决定程序执行的流程。</p><p><img src="/../picture/image-20220730183617885.png" alt="程序计数器的作用"></p><p>​那么我们知道了程序计数器用来控制程序的执行顺序，想一下，分支和循环语句是怎么控制的了？</p><p>​对于顺序执行的语句来说，每执行一个指令，程序计数器的值就自动加1，对于循环和分支来说，程序计数器的值肯定不是按顺序增加的了，接下来我们看一个用于输出一个数的绝对值的出鞥许计数器控制的例子</p><p><img src="/../picture/image-20220730184000119.png" alt="程序计数器控制分支语句"></p><p>​由上图可知，对于循环和分支语句，使用跳转指令来判断是否跳转,机器怎样判断是否跳转，这里就用到了标志寄存器，标志寄存器会保存累加计算之后的结果，标志寄存器的的第一个字节位、第二个字节位、第三个字节位运算结果分别表示正数、零和负数，CPU内部的比较其实是做减法运算的，通过减法运算之后的值表示大小。</p><h3 id="函数调用机制"><a href="#函数调用机制" class="headerlink" title="函数调用机制"></a>函数调用机制</h3><p>​通过上一小节的内容我们知道，分支和循环是由程序计数器和标志寄存器控制的，那么函数调用时怎么控制的了，我们想一下，函数的调用和分支循环语句是否一样？在函数调用结束以后，还要回到调用函数的下一行指令，那么这一步操作，就要比分支和循环复杂，这一操作基本没有办法实现，机器语言用到了call被return指令来解决这一问题，函数调用的时候使用call指令，不使用跳转指令，call指令会把调用函数之后要执行的指令放在栈中，在函数处理完之后，在函数的出口直行return指令，return指令就会把保存在栈中的地址返回到程序计数器中。</p><h3 id="数组内部是怎么调用的"><a href="#数组内部是怎么调用的" class="headerlink" title="数组内部是怎么调用的"></a>数组内部是怎么调用的</h3><p>​在上图CPU寄存器的种类中我们看到了基址寄存器和变址寄存器，通过这两个寄存器，对内存的地址进行了划分，对于一个数组，数组中元素的实际地址我们使用基址寄存器的值+变址寄存器的值来表示实际地址。基址寄存器相当于数组的首地址，变址寄存器相当于索引。</p><p><img src="/../picture/image-20220731085758742.png" alt="数组内部地址的表示"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>​通过上述内容的讲解，相信大家对CPU都有一定的认识和理解，其实CPU处理的功能都很简单，其实CPU能处理的功能如下表所示：</p><p><img src="/../picture/image-20220731090400768.png" alt="机器语言指令的主要类型和功能"></p><h2 id="数据的二进制表示"><a href="#数据的二进制表示" class="headerlink" title="数据的二进制表示"></a>数据的二进制表示</h2>]]></content>
    
    
    
    <tags>
      
      <tag>计算机基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
